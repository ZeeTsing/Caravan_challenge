{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook adapted from https://www.kaggle.com/bguberfain/naive-keras\n",
    "\n",
    "Setup the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from skimage.transform import downscale_local_mean\n",
    "from os.path import join\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'G:/Github/Caravan_challenge/data/train/'\n",
    "mask_dir = 'G:/Github/Caravan_challenge/data/train_masks/'\n",
    "test_dir = 'G:/Github/Caravan_challenge/data/test/'\n",
    "all_images = os.listdir(data_dir)\n",
    "image_size = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator that we will use to read the data from the directory\n",
    "def data_gen_small(data_dir, mask_dir, images, batch_size, dims):\n",
    "        \"\"\"\n",
    "        data_dir: where the actual images are kept\n",
    "        mask_dir: where the actual masks are kept\n",
    "        images: the filenames of the images we want to generate batches from\n",
    "        batch_size: self explanatory\n",
    "        dims: the dimensions in which we want to rescale our images, tuple\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            ix = np.random.choice(np.arange(len(images)), batch_size)\n",
    "            imgs = []\n",
    "            labels = []\n",
    "            for i in ix:\n",
    "                # images\n",
    "                original_img = load_img(data_dir + images[i])\n",
    "                resized_img = original_img.resize(dims)\n",
    "                array_img = img_to_array(resized_img)/255\n",
    "                imgs.append(array_img)\n",
    "                \n",
    "                # masks\n",
    "                original_mask = load_img(mask_dir + images[i].split(\".\")[0] + '_mask.gif')\n",
    "                resized_mask = original_mask.resize(dims)\n",
    "                array_mask = img_to_array(resized_mask)/255\n",
    "                labels.append(array_mask[:, :, 0])\n",
    "            imgs = np.array(imgs)\n",
    "            labels = np.array(labels)\n",
    "            yield imgs, labels.reshape(-1, dims[0], dims[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = data_gen_small(data_dir, mas k_dir, train_images, 5, (image_size, image_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define our own dice_coef (F1) for the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's use Tensorflow to write our own dice_coeficcient metric\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1e-5\n",
    "    \n",
    "    y_true = tf.round(tf.reshape(y_true, [-1]))\n",
    "    y_pred = tf.round(tf.reshape(y_pred, [-1]))\n",
    "    \n",
    "    isct = tf.reduce_sum(y_true * y_pred)\n",
    "    \n",
    "    return 2 * isct / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a simple CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "model = Sequential()\n",
    "model.add( Conv2D(16, 3, activation='relu', padding='same', input_shape=(img_1, img_2, 9)) )\n",
    "model.add( Conv2D(32, 3, activation='relu', padding='same') )\n",
    "model.add( Conv2D(1, 5, activation='sigmoid', padding='same') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam', loss = BinaryCrossentropy(), metrics=['accuracy',doce_coef])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 1280, 1918, 16)    1312      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1280, 1918, 32)    4640      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 1280, 1918, 1)     801       \n",
      "=================================================================\n",
      "Total params: 6,753\n",
      "Trainable params: 6,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25 samples, validate on 7 samples\n",
      "Epoch 1/15\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_gen, epochs=24, steps_per_epoch=212, validation_split = 0.25,  verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = model.history.history['loss']\n",
    "test_loss = model.history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = model.history.history['accuracy']\n",
    "test_loss = model.history.history['val_accuracy']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Accuracy', 'Val Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
