{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread\n",
    "from skimage.transform import downscale_local_mean\n",
    "from os.path import join\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder = 'G:/Github/Caravan_challenge/data'\n",
    "\n",
    "df_mask = pd.read_csv(join(input_folder, 'train_masks.csv'), usecols=['img'])\n",
    "\n",
    "ids_train = df_mask['img'].map(lambda s: s.split('_')[0]).unique()\n",
    "\n",
    "imgs_idx = list(range(1, 17))\n",
    "\n",
    "\n",
    "img_1 = 1280\n",
    "img_2 = 1918\n",
    "img_chan = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define helper functions for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_img = lambda im, idx: imread(join(input_folder, 'train', '{}_{:02d}.jpg'.format(im, idx)))\n",
    "load_mask = lambda im, idx: imread(join(input_folder, 'train_masks', '{}_{:02d}_mask.gif'.format(im, idx)))\n",
    "resize = lambda im: downscale_local_mean(im, (img_resize,img_resize) if im.ndim==2 else (img_resize,img_resize,1))\n",
    "mask_image = lambda im, mask: (im * np.expand_dims(mask, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 0\n",
      "Processed 10\n",
      "Processed 20\n",
      "Processed 30\n"
     ]
    }
   ],
   "source": [
    "num_train = 32  # len(ids_train)\n",
    "\n",
    "# Load data for position id=1\n",
    "X = np.empty((num_train, img_1,img_2 , 9), dtype=np.float32)\n",
    "y = np.empty((num_train, img_1, img_2, 1), dtype=np.float32)\n",
    "\n",
    "\n",
    "idx = 1 # Rotation index\n",
    "for i, img_id in enumerate(ids_train[:num_train]):\n",
    "    imgs_id = [load_img(img_id, j) for j in imgs_idx]\n",
    "    \n",
    "    # Input is image + mean image per channel + std image per channel\n",
    "    \n",
    "    X[i, ..., :9] = np.concatenate([imgs_id[idx-1], np.mean(imgs_id, axis=0), np.std(imgs_id, axis=0)], axis=2)\n",
    "    y[i] = np.expand_dims(load_mask(img_id, idx), axis=2) / 255.\n",
    "    if i%10 == 0:\n",
    "        print('Processed {}'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "from tensorflow_addons.metrics import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize input and output\n",
    "X_mean = X_train.mean(axis=(0,1,2), keepdims=True)\n",
    "X_std = X_train.std(axis=(0,1,2), keepdims=True)\n",
    "\n",
    "X_train -= X_mean\n",
    "X_train /= X_std\n",
    "\n",
    "X_val -= X_mean\n",
    "X_val /= X_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a simple CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "\n",
    "model = Sequential()\n",
    "model.add( Conv2D(16, 3, activation='relu', padding='same', input_shape=(img_1, img_2, 9)) )\n",
    "model.add( Conv2D(32, 3, activation='relu', padding='same') )\n",
    "model.add( Conv2D(1, 5, activation='sigmoid', padding='same') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'Adam', loss = BinaryCrossentropy(), metrics=['accuracy',F1Score(num_classes = 2,average ='micro')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 1280, 1918, 16)    1312      \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 1280, 1918, 32)    4640      \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1280, 1918, 1)     801       \n",
      "=================================================================\n",
      "Total params: 6,753\n",
      "Trainable params: 6,753\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25 samples, validate on 7 samples\n",
      "Epoch 1/15\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val), batch_size=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = model.history.history['loss']\n",
    "test_loss = model.history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss = model.history.history['accuracy']\n",
    "test_loss = model.history.history['val_accuracy']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Accuracy', 'Val Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
