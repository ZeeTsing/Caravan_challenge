{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unet_Carvana_full_fullsize.ipynb",
      "provenance": [],
      "mount_file_id": "1IlbOWmOKp8tZuUOBWYYiqJOnrp6mSgLs",
      "authorship_tag": "ABX9TyO/iPr4h3wWhmUhv8Wq9cYY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZeeTsing/Carvana_challenge/blob/master/3_Unet_trained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVTkm4oFuQLN",
        "colab_type": "text"
      },
      "source": [
        "# Setting up notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5nM5eLUpAbC",
        "colab_type": "code",
        "outputId": "f4a77f17-35aa-4ec2-8a65-7537348c885c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ-UPBRepV2c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_addons as tfa\n",
        "import PIL\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Input, MaxPool2D, UpSampling2D, Concatenate, Conv2DTranspose\n",
        "from tensorflow.keras import Sequential,Model\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "import tensorflow as tf\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n",
        "import os\n",
        "from tensorflow.keras.backend import flatten\n",
        "import tensorflow.keras.backend as K\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vXZiP9tuVaM",
        "colab_type": "text"
      },
      "source": [
        "# Prepare data generator (no augmentation)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRnv2O_upYZ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dir = '/content/drive/My Drive/car_data/train/'\n",
        "mask_dir = '/content/drive/My Drive/car_data/train_masks/'\n",
        "\n",
        "all_images = os.listdir(data_dir)\n",
        "\n",
        "to_train = 1 # ratio of number of train set images to use\n",
        "total_train_images = all_images[:int(len(all_images)*to_train)]\n",
        "\n",
        "WIDTH = 512  #  actual : 1918//1920 divisive by 64\n",
        "HEIGHT = 512 # actual : 1280\n",
        "BATCH_SIZE = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2quls8NOptdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split train set and test set\n",
        "train_images, validation_images = train_test_split(total_train_images, train_size=0.8, test_size=0.2,random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmS31FAbI-YR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generator that we will use to read the data from the directory\n",
        "def data_gen_small(data_dir, mask_dir, images, batch_size, dims):\n",
        "        \"\"\"\n",
        "        data_dir: where the actual images are kept\n",
        "        mask_dir: where the actual masks are kept\n",
        "        images: the filenames of the images we want to generate batches from\n",
        "        batch_size: self explanatory\n",
        "        dims: the dimensions in which we want to rescale our images, tuple\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            ix = np.random.choice(np.arange(len(images)), batch_size)\n",
        "            imgs = []\n",
        "            labels = []\n",
        "            for i in ix:\n",
        "                # images\n",
        "                original_img = load_img(data_dir + images[i])\n",
        "                resized_img = original_img.resize(dims)\n",
        "                array_img = img_to_array(resized_img)/255\n",
        "                imgs.append(array_img)\n",
        "                \n",
        "                # masks\n",
        "                original_mask = load_img(mask_dir + images[i].split(\".\")[0] + '_mask.gif')\n",
        "                resized_mask = original_mask.resize(dims)\n",
        "                array_mask = img_to_array(resized_mask)/255\n",
        "                labels.append(array_mask[:, :, 0])\n",
        "\n",
        "            imgs = np.array(imgs)\n",
        "            labels = np.array(labels)\n",
        "            yield imgs, labels.reshape(-1, dims[0], dims[1], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EoBJOAfFj76S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generator that we will use to read the data from the directory with random augmentation\n",
        "def data_gen_aug(data_dir, mask_dir, images, batch_size, dims):\n",
        "        \"\"\"\n",
        "        data_dir: where the actual images are kept\n",
        "        mask_dir: where the actual masks are kept\n",
        "        images: the filenames of the images we want to generate batches from\n",
        "        batch_size: self explanatory\n",
        "        dims: the dimensions in which we want to rescale our images, tuple\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            ix = np.random.choice(np.arange(len(images)), batch_size)\n",
        "            imgs = []\n",
        "            labels = []\n",
        "            for i in ix:\n",
        "                # read images and masks\n",
        "                original_img = load_img(data_dir + images[i])\n",
        "                original_mask = load_img(mask_dir + images[i].split(\".\")[0] + '_mask.gif')\n",
        "                \n",
        "                # transform into ideal sizes\n",
        "                resized_img = original_img.resize(dims)\n",
        "                resized_mask = original_mask.resize(dims)\n",
        "              \n",
        "                # add random augmentation > here we only flip horizontally\n",
        "                if np.random.random() < 0.5:\n",
        "                  resized_img = resized_img.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
        "                  resized_mask = resized_mask.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "                array_img = img_to_array(resized_img)/255\n",
        "                array_mask = img_to_array(resized_mask)/255\n",
        "\n",
        "                imgs.append(array_img)\n",
        "                labels.append(array_mask[:, :, 0])\n",
        "                \n",
        "            imgs = np.array(imgs)\n",
        "            labels = np.array(labels)\n",
        "            yield imgs, labels.reshape(-1, dims[0], dims[1], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baC_mlppp5LB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generator for train and validation data set\n",
        "train_gen = data_gen_aug(data_dir, mask_dir, train_images, BATCH_SIZE, (WIDTH, HEIGHT))\n",
        "val_gen = data_gen_small(data_dir, mask_dir, validation_images, BATCH_SIZE, (WIDTH, HEIGHT))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEDhS9TvuHid",
        "colab_type": "text"
      },
      "source": [
        "# Set up Unet model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdLWK4FHubuF",
        "colab_type": "text"
      },
      "source": [
        "Define down and up layers that will be used in Unet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eD3PryxOCACg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def down(input_layer, filters, pool=True):\n",
        "    conv1 = Conv2D(filters, (3, 3), padding='same', activation='relu')(input_layer)\n",
        "    residual = Conv2D(filters, (3, 3), padding='same', activation='relu')(conv1)\n",
        "    if pool:\n",
        "        max_pool = MaxPool2D()(residual)\n",
        "        return max_pool, residual\n",
        "    else:\n",
        "        return residual\n",
        "\n",
        "def up(input_layer, residual, filters):\n",
        "    filters=int(filters)\n",
        "    upsample = UpSampling2D()(input_layer)\n",
        "    upconv = Conv2D(filters, kernel_size=(2, 2), padding=\"same\")(upsample)\n",
        "    concat = Concatenate(axis=3)([residual, upconv])\n",
        "    conv1 = Conv2D(filters, (3, 3), padding='same', activation='relu')(concat)\n",
        "    conv2 = Conv2D(filters, (3, 3), padding='same', activation='relu')(conv1)\n",
        "    return conv2  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx3z9JdAugdW",
        "colab_type": "code",
        "outputId": "2c876d7d-3f88-4ca6-98b2-31727a5bc56f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Make a custom U-nets implementation.\n",
        "filters = 64\n",
        "input_layer = Input(shape = [WIDTH, HEIGHT, 3])\n",
        "layers = [input_layer]\n",
        "residuals = []\n",
        "\n",
        "# Down 1\n",
        "d1, res1 = down(input_layer, filters)\n",
        "residuals.append(res1)\n",
        "\n",
        "filters *= 2\n",
        "\n",
        "# Down 2\n",
        "d2, res2 = down(d1, filters)\n",
        "residuals.append(res2)\n",
        "\n",
        "filters *= 2\n",
        "\n",
        "# Down 3\n",
        "d3, res3 = down(d2, filters)\n",
        "residuals.append(res3)\n",
        "\n",
        "filters *= 2\n",
        "\n",
        "# Down 4\n",
        "d4, res4 = down(d3, filters)\n",
        "residuals.append(res4)\n",
        "\n",
        "filters *= 2\n",
        "\n",
        "# Down 5\n",
        "d5 = down(d4, filters, pool=False)\n",
        "\n",
        "# Up 1\n",
        "up1 = up(d5, residual=residuals[-1], filters=filters/2)\n",
        "filters /= 2\n",
        "\n",
        "# Up 2\n",
        "up2 = up(up1, residual=residuals[-2], filters=filters/2)\n",
        "\n",
        "filters /= 2\n",
        "\n",
        "# Up 3\n",
        "up3 = up(up2, residual=residuals[-3], filters=filters/2)\n",
        "\n",
        "filters /= 2\n",
        "\n",
        "# Up 4\n",
        "up4 = up(up3, residual=residuals[-4], filters=filters/2)\n",
        "\n",
        "out = Conv2D(filters=1, kernel_size=(1, 1), activation=\"sigmoid\")(up4)\n",
        "\n",
        "model = Model(input_layer, out)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 512, 512, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 512, 512, 64) 1792        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 512, 512, 64) 36928       conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 256, 256, 64) 0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 256, 256, 128 73856       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 256, 256, 128 147584      conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 128 0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 128, 128, 256 295168      max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 128, 128, 256 590080      conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 64, 64, 512)  1180160     max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 64, 64, 512)  2359808     conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 1024) 4719616     max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 1024) 9438208     conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d (UpSampling2D)    (None, 64, 64, 1024) 0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 64, 64, 512)  2097664     up_sampling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 64, 64, 1024) 0           conv2d_7[0][0]                   \n",
            "                                                                 conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 64, 64, 512)  4719104     concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 64, 64, 512)  2359808     conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 512 0           conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 128, 128, 256 524544      up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 128, 128, 512 0           conv2d_5[0][0]                   \n",
            "                                                                 conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 128, 128, 256 1179904     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 128, 128, 256 590080      conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 256 0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 256, 256, 128 131200      up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 256, 256, 256 0           conv2d_3[0][0]                   \n",
            "                                                                 conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 256, 256, 128 295040      concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 256, 256, 128 147584      conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, 512, 512, 128 0           conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 512, 512, 64) 32832       up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 512, 512, 128 0           conv2d_1[0][0]                   \n",
            "                                                                 conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 512, 512, 64) 73792       concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 512, 512, 64) 36928       conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 512, 512, 1)  65          conv2d_21[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 31,031,745\n",
            "Trainable params: 31,031,745\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yiF0byj0DNId",
        "colab": {}
      },
      "source": [
        "# Now let's use Tensorflow to write our own dice_coeficcient metric, which is a effective indicator of how much two sets overlap with each other\n",
        "def dice_coef(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = flatten(y_true)\n",
        "    y_pred_f = flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3Sd2VKBvIIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Include the epoch in the file name (uses `str.format`)\n",
        "checkpoint_path = \"/content/drive/My Drive/car_data/unet_cp_full_512batch5/cp-{epoch:04d}.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights every epochs\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path, \n",
        "    verbose=1, \n",
        "    save_weights_only=True,\n",
        "    save_freq='epoch')\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8,\n",
        "                                              restore_best_weights=False\n",
        "                                              )\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                                   factor=0.2,\n",
        "                                   patience=3,\n",
        "                                   verbose=1,\n",
        "                                   min_delta=1e-3,min_lr = 1e-6\n",
        "                                   )\n",
        "\n",
        "adam = tf.keras.optimizers.Adam(learning_rate=0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOueKWFvsFNK",
        "colab_type": "text"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOKAy9GNrhyF",
        "colab_type": "text"
      },
      "source": [
        "Load weights and continue training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJaawm5krur0",
        "colab_type": "code",
        "outputId": "35454bba-e2c9-4e85-cd51-b731a6eb20db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "latest"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/car_data/unet_cp_full_512batch5/cp-0016.ckpt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MC8tsrRErhYs",
        "colab_type": "code",
        "outputId": "695ba6fd-907d-46f9-8bba-74e09f083c6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model.load_weights(latest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f355dda2f98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFGgzoghvQvr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = adam, loss = BinaryCrossentropy(), metrics=['accuracy',dice_coef])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxjcKy78vWBW",
        "colab_type": "code",
        "outputId": "b9da6867-84fe-4bf1-a4be-a9dc83ce948c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train_gen, callbacks=[cp_callback,early_stop,reduce_lr],\n",
        "                    steps_per_epoch=np.ceil(float(len(train_images)) / float(BATCH_SIZE)),\n",
        "                    epochs=100,\n",
        "                    validation_steps=np.ceil(float(len(validation_images)) / float(BATCH_SIZE)),\n",
        "                    validation_data = val_gen)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 814.0 steps, validate for 204.0 steps\n",
            "Epoch 1/100\n",
            "813/814 [============================>.] - ETA: 0s - loss: 0.0071 - accuracy: 0.9935 - dice_coef: 0.9903\n",
            "Epoch 00001: saving model to /content/drive/My Drive/car_data/unet_cp_full_512batch5/cp-0001.ckpt\n",
            "814/814 [==============================] - 681s 836ms/step - loss: 0.0071 - accuracy: 0.9935 - dice_coef: 0.9903 - val_loss: 0.0060 - val_accuracy: 0.9939 - val_dice_coef: 0.9919\n",
            "Epoch 2/100\n",
            "813/814 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9940 - dice_coef: 0.9922\n",
            "Epoch 00002: saving model to /content/drive/My Drive/car_data/unet_cp_full_512batch5/cp-0002.ckpt\n",
            "814/814 [==============================] - 681s 837ms/step - loss: 0.0055 - accuracy: 0.9940 - dice_coef: 0.9922 - val_loss: 0.0060 - val_accuracy: 0.9939 - val_dice_coef: 0.9920\n",
            "Epoch 3/100\n",
            "813/814 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9939 - dice_coef: 0.9917\n",
            "Epoch 00003: saving model to /content/drive/My Drive/car_data/unet_cp_full_512batch5/cp-0003.ckpt\n",
            "814/814 [==============================] - 679s 834ms/step - loss: 0.0059 - accuracy: 0.9939 - dice_coef: 0.9917 - val_loss: 0.0063 - val_accuracy: 0.9937 - val_dice_coef: 0.9914\n",
            "Epoch 4/100\n",
            "813/814 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9941 - dice_coef: 0.9925\n",
            "Epoch 00004: saving model to /content/drive/My Drive/car_data/unet_cp_full_512batch5/cp-0004.ckpt\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
            "814/814 [==============================] - 680s 835ms/step - loss: 0.0052 - accuracy: 0.9941 - dice_coef: 0.9925 - val_loss: 0.0055 - val_accuracy: 0.9940 - val_dice_coef: 0.9924\n",
            "Epoch 5/100\n",
            "813/814 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9942 - dice_coef: 0.9933\n",
            "Epoch 00005: saving model to /content/drive/My Drive/car_data/unet_cp_full_512batch5/cp-0005.ckpt\n",
            "814/814 [==============================] - 681s 836ms/step - loss: 0.0046 - accuracy: 0.9942 - dice_coef: 0.9933 - val_loss: 0.0053 - val_accuracy: 0.9940 - val_dice_coef: 0.9930\n",
            "Epoch 6/100\n",
            "813/814 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9943 - dice_coef: 0.9935\n",
            "Epoch 00006: saving model to /content/drive/My Drive/car_data/unet_cp_full_512batch5/cp-0006.ckpt\n",
            "814/814 [==============================] - 679s 834ms/step - loss: 0.0045 - accuracy: 0.9943 - dice_coef: 0.9935 - val_loss: 0.0053 - val_accuracy: 0.9940 - val_dice_coef: 0.9931\n",
            "Epoch 7/100\n",
            "813/814 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9943 - dice_coef: 0.9936\n",
            "Epoch 00007: saving model to /content/drive/My Drive/car_data/unet_cp_full_512batch5/cp-0007.ckpt\n",
            "\n",
            "Epoch 00007: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
            "814/814 [==============================] - 679s 834ms/step - loss: 0.0044 - accuracy: 0.9943 - dice_coef: 0.9936 - val_loss: 0.0051 - val_accuracy: 0.9941 - val_dice_coef: 0.9932\n",
            "Epoch 8/100\n",
            "813/814 [============================>.] - ETA: 0s - loss: 0.0043 - accuracy: 0.9943 - dice_coef: 0.9937\n",
            "Epoch 00008: saving model to /content/drive/My Drive/car_data/unet_cp_full_512batch5/cp-0008.ckpt\n",
            "814/814 [==============================] - 679s 835ms/step - loss: 0.0043 - accuracy: 0.9943 - dice_coef: 0.9937 - val_loss: 0.0051 - val_accuracy: 0.9940 - val_dice_coef: 0.9933\n",
            "Epoch 9/100\n",
            "813/814 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9943 - dice_coef: 0.9938\n",
            "Epoch 00009: saving model to /content/drive/My Drive/car_data/unet_cp_full_512batch5/cp-0009.ckpt\n",
            "814/814 [==============================] - 681s 836ms/step - loss: 0.0042 - accuracy: 0.9943 - dice_coef: 0.9938 - val_loss: 0.0051 - val_accuracy: 0.9941 - val_dice_coef: 0.9933\n",
            "Epoch 10/100\n",
            "813/814 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9943 - dice_coef: 0.9939\n",
            "Epoch 00010: saving model to /content/drive/My Drive/car_data/unet_cp_full_512batch5/cp-0010.ckpt\n",
            "814/814 [==============================] - 680s 835ms/step - loss: 0.0042 - accuracy: 0.9943 - dice_coef: 0.9939 - val_loss: 0.0050 - val_accuracy: 0.9942 - val_dice_coef: 0.9934\n",
            "Epoch 11/100\n",
            "813/814 [============================>.] - ETA: 0s - loss: 0.0042 - accuracy: 0.9944 - dice_coef: 0.9939\n",
            "Epoch 00011: saving model to /content/drive/My Drive/car_data/unet_cp_full_512batch5/cp-0011.ckpt\n",
            "814/814 [==============================] - 679s 835ms/step - loss: 0.0042 - accuracy: 0.9944 - dice_coef: 0.9939 - val_loss: 0.0051 - val_accuracy: 0.9941 - val_dice_coef: 0.9934\n",
            "Epoch 12/100\n",
            "813/814 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9943 - dice_coef: 0.9940\n",
            "Epoch 00012: saving model to /content/drive/My Drive/car_data/unet_cp_full_512batch5/cp-0012.ckpt\n",
            "814/814 [==============================] - 679s 834ms/step - loss: 0.0041 - accuracy: 0.9943 - dice_coef: 0.9940 - val_loss: 0.0052 - val_accuracy: 0.9940 - val_dice_coef: 0.9934\n",
            "Epoch 13/100\n",
            "813/814 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9943 - dice_coef: 0.9940\n",
            "Epoch 00013: saving model to /content/drive/My Drive/car_data/unet_cp_full_512batch5/cp-0013.ckpt\n",
            "\n",
            "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
            "814/814 [==============================] - 680s 835ms/step - loss: 0.0041 - accuracy: 0.9943 - dice_coef: 0.9940 - val_loss: 0.0051 - val_accuracy: 0.9941 - val_dice_coef: 0.9935\n",
            "Epoch 14/100\n",
            "813/814 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9943 - dice_coef: 0.9940\n",
            "Epoch 00014: saving model to /content/drive/My Drive/car_data/unet_cp_full_512batch5/cp-0014.ckpt\n",
            "814/814 [==============================] - 679s 834ms/step - loss: 0.0041 - accuracy: 0.9943 - dice_coef: 0.9940 - val_loss: 0.0050 - val_accuracy: 0.9941 - val_dice_coef: 0.9935\n",
            "Epoch 15/100\n",
            "813/814 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9943 - dice_coef: 0.9940\n",
            "Epoch 00015: saving model to /content/drive/My Drive/car_data/unet_cp_full_512batch5/cp-0015.ckpt\n",
            "814/814 [==============================] - 680s 836ms/step - loss: 0.0041 - accuracy: 0.9943 - dice_coef: 0.9940 - val_loss: 0.0052 - val_accuracy: 0.9941 - val_dice_coef: 0.9934\n",
            "Epoch 16/100\n",
            "813/814 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9944 - dice_coef: 0.9940\n",
            "Epoch 00016: saving model to /content/drive/My Drive/car_data/unet_cp_full_512batch5/cp-0016.ckpt\n",
            "814/814 [==============================] - 679s 834ms/step - loss: 0.0041 - accuracy: 0.9944 - dice_coef: 0.9940 - val_loss: 0.0051 - val_accuracy: 0.9941 - val_dice_coef: 0.9935\n",
            "Epoch 17/100\n",
            "451/814 [===============>..............] - ETA: 4:18 - loss: 0.0041 - accuracy: 0.9943 - dice_coef: 0.9940"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wsRyDgDp_xQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}